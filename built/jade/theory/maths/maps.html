<h1 id="linear-maps"><span class="header-section-number">1</span> Linear maps</h1>
<h2 id="homomorphisms-of-vector-spaces"><span class="header-section-number">1.1</span> Homomorphisms of vector spaces</h2>
<h3 id="linear-maps-1"><span class="header-section-number">1.1.1</span> Linear maps</h3>
<h4 id="homomorphisms-between-vector-spaces"><span class="header-section-number">1.1.1.1</span> Homomorphisms between vector spaces</h4>
<p>Homomorphisms map between algebras, preserving the underlying structure.</p>
<p>A homomorphism vetween vector space <span class="math inline"><em>V</em></span> and vector space <span class="math inline"><em>W</em></span> can be described as:</p>
<p><span class="math inline">hom(<em>V</em>, <em>W</em>)</span></p>
<p>Homomorphism between vector spaces must preserve the group-like structure of the vector space.</p>
<p><span class="math inline"><em>f</em>(<em>u</em> + <em>v</em>)=<em>f</em>(<em>u</em>)+<em>f</em>(<em>v</em>)</span></p>
<p>The homomorphism must also preserve scalar multiplication.</p>
<p><span class="math inline"><em>f</em>(<em>α</em><em>v</em>)=<em>α</em><em>f</em>(<em>v</em>)</span></p>
<p>A linear map (or function) is a map from one input to an output which preserves addition and scalar multiplication.</p>
<p>That is if function <span class="math inline"><em>f</em></span> is linear then:</p>
<p><br /><span class="math display"><em>f</em>(<em>a</em><em>M</em> + <em>b</em><em>N</em>)=<em>a</em><em>f</em>(<em>M</em>)+<em>b</em><em>f</em>(<em>N</em>)</span><br /></p>
<h4 id="alternative-names-for-homomorphisms"><span class="header-section-number">1.1.1.2</span> Alternative names for homomorphisms</h4>
<p>Vector spaces homomorphisms are also called linear maps or linear functions.</p>
<h3 id="homomorphisms-form-a-vector-space"><span class="header-section-number">1.1.2</span> Homomorphisms form a vector space</h3>
<p>If we can can show that scalars can act on morphisms, then we can shwn that morphisms on a vector space are themselves a vector space.</p>
<p>Scalars can act on morphisms, and so morphisms of vector spaces are themselves vector spaces.</p>
<h4 id="dimensions-of-homomorphisms"><span class="header-section-number">1.1.2.1</span> Dimensions of homomorphisms</h4>
<p>We can identify the dimensionality of this new vector space from the dimensions of the original vector spaces.</p>
<p><span class="math inline">dim(hom(<em>V</em>, <em>W</em>)) = dim <em>V</em>dim <em>W</em></span></p>
<h3 id="the-pseudo-inverse"><span class="header-section-number">1.1.3</span> The pseudo-inverse</h3>
<p>The definition of the inverse is that:</p>
<p><span class="math inline"><em>M</em><em>M</em><sup>−1</sup> = <em>I</em></span></p>
<p><span class="math inline"><em>M</em><sup>−1</sup><em>M</em> = <em>I</em></span></p>
<p>We also have:</p>
<p><span class="math inline"><em>M</em><em>M</em><sup>−1</sup><em>M</em> = <em>M</em></span></p>
<p><span class="math inline"><em>M</em><sup>−1</sup><em>M</em><em>M</em><sup>−1</sup> = <em>M</em><sup>−1</sup></span></p>
<h4 id="the-inverse-of-a-homomorphism"><span class="header-section-number">1.1.3.1</span> The inverse of a homomorphism</h4>
<p>Generally we don’t have inverses of homomorphisms as the number of dimensions are different.</p>
<p>We can, however, find a matrix <span class="math inline"><em>M</em><sup>+</sup></span> which satisfies:</p>
<p><span class="math inline"><em>M</em><em>M</em><sup>+</sup><em>M</em> = <em>M</em></span></p>
<p><span class="math inline"><em>M</em><sup>+</sup><em>M</em><em>M</em><sup>+</sup> = <em>M</em><sup>+</sup></span></p>
<p>This is the pseudo-inverse.</p>
<h3 id="linear-and-affine-functions"><span class="header-section-number">1.1.4</span> Linear and affine functions</h3>
<h4 id="linear-maps-2"><span class="header-section-number">1.1.4.1</span> Linear maps</h4>
<p>Linear maps can be written as:</p>
<p><span class="math inline"><em>v</em> = <em>M</em><em>u</em></span></p>
<p>These go through the origin. That is, if <span class="math inline"><em>u</em> = 0</span> then <span class="math inline"><em>v</em> = 0</span>.</p>
<h4 id="affine-function"><span class="header-section-number">1.1.4.2</span> Affine function</h4>
<p>Affine functions are more general than linear maps. They can be written as:</p>
<p><span class="math inline"><em>v</em> = <em>M</em><em>u</em> + <em>c</em></span></p>
<p>Where <span class="math inline"><em>c</em></span> is a vector in the same space as <span class="math inline"><em>v</em></span>.</p>
<p>Affine functions where <span class="math inline"><em>c</em> ≠ 0</span> are not linear maps. They are not homomorphisms which preserve the structure of the vector space.</p>
<p>If we multiply <span class="math inline"><em>u</em></span> by a scalar <span class="math inline"><em>s</em></span>, then <span class="math inline"><em>v</em></span> will not increase by the same proportion.</p>
<h3 id="singular-value-decomposition"><span class="header-section-number">1.1.5</span> Singular value decomposition</h3>
<p>The singular value decomposition of <span class="math inline"><em>m</em> × <em>n</em></span> matrix <span class="math inline"><em>M</em></span> is:</p>
<p><span class="math inline"><em>M</em> = <em>U</em><em>Σ</em><em>V</em><sup>*</sup></span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline"><em>U</em></span> is a unitary matrix (<span class="math inline"><em>m</em> × <em>m</em></span>)</p></li>
<li><p><span class="math inline"><em>Σ</em></span> is a diagonal matrix with non-negative real numbers (<span class="math inline"><em>m</em> × <em>n</em></span>)</p></li>
<li><p><span class="math inline"><em>V</em></span> is a unitary matrix (<span class="math inline"><em>n</em> × <em>n</em></span>)</p></li>
</ul>
<p><span class="math inline"><em>Σ</em></span> is unique. <span class="math inline"><em>U</em></span> and <span class="math inline"><em>V</em></span> are not.</p>
<h4 id="properties"><span class="header-section-number">1.1.5.1</span> Properties</h4>
<p><span class="math inline"><em>M</em><sup>*</sup><em>M</em> = <em>U</em><em>Σ</em><sup>2</sup><em>U</em><sup>*</sup></span></p>
<p><span class="math inline">(<em>M</em><sup>*</sup><em>M</em>)<sup>−1</sup> = <em>V</em><em>Σ</em><sup>−2</sup><em>V</em><sup>*</sup></span></p>
<h4 id="calculating-the-svd"><span class="header-section-number">1.1.5.2</span> Calculating the SVD</h4>
<p>The SVD is generally calculated iteratively.</p>
<h3 id="identity-matrix-and-the-kronecker-delta"><span class="header-section-number">1.1.6</span> Identity matrix and the Kronecker delta</h3>
<h4 id="the-kronecker-delta"><span class="header-section-number">1.1.6.1</span> The Kronecker delta</h4>
<p>The Kronecker delta is defined as:</p>
<p>p<span class="math inline"><em>δ</em><sub><em>i</em><em>j</em></sub> = 0</span> where <span class="math inline"><em>i</em> ≠ <em>j</em></span></p>
<p><span class="math inline"><em>δ</em><sub><em>i</em><em>j</em></sub> = 1</span> where <span class="math inline"><em>i</em> = <em>j</em></span></p>
<p>We can use this to define matrices. For example for the identity matrix:</p>
<p><span class="math inline"><em>I</em><sub><em>i</em><em>j</em></sub> = <em>δ</em><sub><em>i</em><em>j</em></sub></span></p>
<h4 id="identity-matrix"><span class="header-section-number">1.1.6.2</span> Identity matrix</h4>
<p>A square matrix where every element is <span class="math inline">0</span> except where <span class="math inline"><em>i</em> = <em>j</em></span>. There is one for each square matrix.</p>
<p><span class="math inline">$I=\begin{bmatrix}1&amp; 0&amp;...&amp;0\\0 &amp; 1&amp;...&amp;0\\...&amp;...&amp;...&amp;...\\0&amp;0&amp;...&amp;1\end{bmatrix}$</span></p>
