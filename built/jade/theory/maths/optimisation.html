<h1 id="optimisation"><span class="header-section-number">1</span> Optimisation</h1>
<h2 id="introduction-to-optimisation"><span class="header-section-number">1.1</span> Introduction to optimisation</h2>
<h3 id="introduction-to-unconstrained-optimisation"><span class="header-section-number">1.1.1</span> Introduction to unconstrained optimisation</h3>
<h4 id="goals"><span class="header-section-number">1.1.1.1</span> Goals</h4>
<p>We want to identify either the maximum or the minimum.</p>
<p>There exist local minima and global minima.</p>
<h4 id="optimising-through-limits"><span class="header-section-number">1.1.1.2</span> Optimising through limits</h4>
<p>If we are looking to minimise a function, and the limits are <span class="math inline">∞</span> or <span class="math inline">−∞</span> then we can optimise by taking large or small values.</p>
<p>We can examine this for each variable.</p>
<p>This also applies for maximising a function.</p>
<h4 id="optimisation-through-stationary-points"><span class="header-section-number">1.1.1.3</span> Optimisation through stationary points</h4>
<p>Stationary points of a function are points where marginal changes do not have an impact on the value of the function. As a result they are either local maxima or minima.</p>
<h4 id="optimisation-through-algorithms"><span class="header-section-number">1.1.1.4</span> Optimisation through algorithms</h4>
<p>If we cannot identify stationary points easily, we can instead use algorithms to identify optima.</p>
<h4 id="stationary-points-of-strictly-concave-and-convex-functions"><span class="header-section-number">1.1.1.5</span> Stationary points of strictly concave and convex functions</h4>
<p>If a function is strictly concave it will only have one stationary point, a local, and global, maxima.</p>
<p>If a function is strictly convex it will only have one stationary point, a local, and global, minima.</p>
<h3 id="local-optima"><span class="header-section-number">1.1.2</span> Local optima</h3>
<h3 id="optimising-convex-functions"><span class="header-section-number">1.1.3</span> Optimising convex functions</h3>
<h3 id="constrained-optimisation"><span class="header-section-number">1.1.4</span> Constrained optimisation</h3>
<h3 id="analytic-optimisation"><span class="header-section-number">1.1.5</span> Analytic optimisation</h3>
<h4 id="convex-and-concave-functions"><span class="header-section-number">1.1.5.1</span> Convex and concave functions</h4>
<p>Convex functions only have one minimum, and concave functions have only one maximum.</p>
<p>If a function is not concave or convex, it may have multiple minima</p>
<p>If a function is convex, then there is only one critical point – the local minimum. We can identify this this by looking for critical points using first-order conditions.</p>
<p>Similarly, if a function is concave, then there is only one critical point – the local maximum.</p>
<p>We can identify whether a function is concave or convex by evaluating the Hessian matrix.</p>
<h4 id="evaluating-multiple-local-optima"><span class="header-section-number">1.1.5.2</span> Evaluating multiple local optima</h4>
<p>We can evaluate each of the local minima or maxima, and compare the sizes.</p>
<p>We can identify these by taking partial derivatives of the function in question and identifying where this function is equal to zero.</p>
<p><span class="math inline"><em>u</em> = <em>f</em>(<em>x</em>)</span></p>
<p><span class="math inline">$u_{x_i}=\frac{\delta f}{\delta x_i}=0$</span></p>
<p>We can then solve this bundle of equations to find the stationary values of <span class="math inline"><em>x</em></span>.</p>
<p>After identifying the vector <span class="math inline"><em>x</em></span> for these points we can then determine whether or not the points are minima or maxima by examining the second derivative at these points. If it is positive it is a local minima, and therefore not an optimal point. Points beyond these will be higher, and may be higher than any local maxima.</p>
<h2 id="unconstrained-optimisation-of-differentiable-functions"><span class="header-section-number">1.2</span> Unconstrained optimisation of differentiable functions</h2>
<h3 id="stationary-points-and-first-order-conditions"><span class="header-section-number">1.2.1</span> Stationary points and first-order conditions</h3>
<h3 id="stationary-points-and-first-order-conditions-1"><span class="header-section-number">1.2.2</span> Stationary points and first-order conditions</h3>
<h3 id="stationary-points-and-first-order-conditions-2"><span class="header-section-number">1.2.3</span> Stationary points and first-order conditions</h3>
<h3 id="hessian-matrix"><span class="header-section-number">1.2.4</span> Hessian matrix</h3>
<p>We can take a function and make a matrix of its second order partial derivatives. This is the Hessian matrix, and it describes the local curvature of the function.</p>
<p>If the function <span class="math inline"><em>f</em></span> has <span class="math inline"><em>n</em></span> parameters, the Hessian matrix is <span class="math inline"><em>n</em> × <em>n</em></span>, and is defined as:</p>
<p><span class="math inline">$H_{ij}=\frac{\delta^2 f}{\delta x_i \delta x_j}$</span></p>
<p>If the function is convex, then the Hessian matrix is positive semi-definite for all points, and vice versa.</p>
<p>If the function is concave, then the Hessian matrix is negative semi-definite for all points, and vice versa.</p>
<p>We can diagnose critical points by evaluating the Hessian matrix at those points.</p>
<p>If it is positive definite, it is a local minimum. If it is negative definite it is a local maximum. If there are both positive and negative eigenvalues it is a saddle point.</p>
<h2 id="linear-optimisation"><span class="header-section-number">1.3</span> Linear optimisation</h2>
<h3 id="single-equality-constraint"><span class="header-section-number">1.3.1</span> Single equality constraint</h3>
<h4 id="constrained-optimisation-1"><span class="header-section-number">1.3.1.1</span> Constrained optimisation</h4>
<p>Rather than maximise <span class="math inline"><em>f</em>(<em>x</em>)</span>, we want to maximise <span class="math inline"><em>f</em>(<em>x</em>)</span> subject to <span class="math inline"><em>g</em>(<em>x</em>)=0</span>.</p>
<p>We write this, the Lagrangian, as:</p>
<p><span class="math inline">$\mathcal{L}(x,\lambda )=f(x)-\sum^m_k\lambda_k [g_k(x)-c_k]$</span></p>
<p>We examine the stationary points for both vector <span class="math inline"><em>x</em></span> and <span class="math inline"><em>λ</em></span>. By including the latter we ensure that these points are consistent with the constraints.</p>
<h4 id="solving-the-langrangian-with-one-constraint"><span class="header-section-number">1.3.1.2</span> Solving the Langrangian with one constraint</h4>
<p>Our function is:</p>
<p><span class="math inline">ℒ(<em>x</em>, <em>λ</em>)=<em>f</em>(<em>x</em>)−<em>λ</em>[<em>g</em>(<em>x</em>)−<em>c</em>]</span></p>
<p>The first-order conditions are:</p>
<p><span class="math inline">ℒ<sub><em>λ</em></sub> = −[<em>g</em>(<em>x</em>)−<em>c</em>]</span></p>
<p><span class="math inline">$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}$</span></p>
<p>The solution is stationary so:</p>
<p><span class="math inline">$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}=0$</span></p>
<p><span class="math inline">$\lambda \frac{\delta g}{\delta x_i}=\frac{\delta f}{\delta x_i}$</span></p>
<p><span class="math inline">$\lambda =\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}$</span></p>
<p>Finally, we can use the following in practical applications.</p>
<p><span class="math inline">$\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}=\frac{\frac{\delta f}{\delta x_j}}{\frac{\delta g}{\delta x_j}}$</span></p>
<h3 id="multiple-equality-constraints"><span class="header-section-number">1.3.2</span> Multiple equality constraints</h3>
<h4 id="solving-the-langrangian-with-many-constraints"><span class="header-section-number">1.3.2.1</span> Solving the Langrangian with many constraints</h4>
<p>This time we have:</p>
<p><span class="math inline">$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=0$</span></p>
<p><span class="math inline">$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}=0$</span></p>
<p><span class="math inline">$\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}$</span></p>
<h3 id="inequality-constraints"><span class="header-section-number">1.3.3</span> Inequality constraints</h3>
<h4 id="lagrangians-with-inequality-constraints"><span class="header-section-number">1.3.3.1</span> Lagrangians with inequality constraints</h4>
<p>We can add constraints to an optimisation problem. These constraints can be equality constraints or inequality constraints. We can write constrained optimisation problem as:</p>
<p>Minimise <span class="math inline"><em>f</em>(<em>x</em>)</span> subject to</p>
<p><span class="math inline"><em>g</em><sub><em>i</em></sub>(<em>x</em>)≤0</span> for <span class="math inline"><em>i</em> = 1, …, <em>m</em></span></p>
<p><span class="math inline"><em>h</em><sub><em>i</em></sub>(<em>x</em>)=0</span> for <span class="math inline"><em>i</em> = 1, …, <em>p</em></span></p>
<p>We write the Lagrangian as:</p>
<p><span class="math inline">$\mathcal{L}(x, \lambda, \nu )=f(x)+\sum_{i=1}^m\lambda_i g_i(x)+\sum_{i=1}^p\nu_ih_i(x)$</span></p>
<p>If we try and solve this like a standard Lagrangian, then all of the inequality constraints will instead by equality constraints.</p>
<h4 id="affinity-of-the-lagrangian"><span class="header-section-number">1.3.3.2</span> Affinity of the Lagrangian</h4>
<p>The Lagrangian function is affine with respect to <span class="math inline"><em>λ</em></span> and <span class="math inline"><em>ν</em></span>.</p>
<p><span class="math inline">$\mathcal{L}(x, \lambda, \nu )=f(x)+\sum_{i=1}^m\lambda_i g_i(x)+\sum_{i=1}^p\nu_ih_i(x)$</span></p>
<p><span class="math inline">ℒ<sub><em>λ</em><sub><em>i</em></sub></sub>(<em>x</em>, <em>λ</em>, <em>ν</em>)=<em>g</em><sub><em>i</em></sub>(<em>x</em>)</span></p>
<p><span class="math inline">ℒ<sub><em>ν</em><sub><em>i</em></sub></sub>(<em>x</em>, <em>λ</em>, <em>ν</em>)=<em>h</em><sub><em>i</em></sub>(<em>x</em>)</span></p>
<p>As the partial differential is constant, the partial differential is an affine function.</p>
<h3 id="primal-and-dual-problems"><span class="header-section-number">1.3.4</span> Primal and dual problems</h3>
<h4 id="the-primal-problem"><span class="header-section-number">1.3.4.1</span> The primal problem</h4>
<p>We already have this.</p>
<h4 id="the-dual-problem"><span class="header-section-number">1.3.4.2</span> The dual problem</h4>
<p>We can define the Lagrangian dual function:</p>
<p><span class="math inline"><em>g</em>(<em>λ</em>, <em>ν</em>)=inf<sub><em>x</em> ∈ <em>X</em></sub>ℒ(<em>x</em>, <em>λ</em>, <em>ν</em>)</span></p>
<p>That is, we have a function which chooses the returns the value of the optimised Lagrangian, given the values of <span class="math inline"><em>λ</em></span> and <span class="math inline"><em>ν</em></span>.</p>
<p>This is an unconstrained function.</p>
<p>We can prove this function is concave (how?).</p>
<p>The infimum of a set of concave (and therefore also affine) functions is concave.</p>
<p>The supremum of a set of convex (and therefore also affine) functions is convex.</p>
<p>Given a function with inputs <span class="math inline"><em>x</em></span>, what values of <span class="math inline"><em>x</em></span> maximise the function?</p>
<p>We explore constrained and unconstrained optimisation. The former is where restrictions are placed on vector <span class="math inline"><em>x</em></span>, such as a budget constraint in economics.</p>
<h4 id="the-dual-problem-is-concave"><span class="header-section-number">1.3.4.3</span> The dual problem is concave</h4>
<h4 id="the-duality-gap"><span class="header-section-number">1.3.4.4</span> The duality gap</h4>
<p>We refer to the optimal solution for the primary problem as <span class="math inline"><em>p</em><sup>*</sup></span>, and the optimal solution for the dual problem as <span class="math inline"><em>d</em><sup>*</sup></span>.</p>
<p>The duality gap is <span class="math inline"><em>p</em><sup>*</sup> − <em>d</em><sup>*</sup></span>.</p>
<h3 id="complementary-slackness-for-linear-optimisation"><span class="header-section-number">1.3.5</span> Complementary slackness for linear optimisation</h3>
<h3 id="farkas-lemma"><span class="header-section-number">1.3.6</span> Farkas’ lemma</h3>
<p>We have matrix <span class="math inline"><em>A</em></span> and vector <span class="math inline"><em>b</em></span>.</p>
<p>Either:</p>
<ul>
<li><p><span class="math inline"><em>A</em><em>x</em> = <em>b</em></span>; <span class="math inline"><em>x</em> ≥ 0</span></p></li>
<li><p><span class="math inline"><em>A</em><sup><em>T</em></sup><em>y</em> ≥ 0</span>; <span class="math inline"><em>b</em><sup><em>T</em></sup><em>y</em> &lt; 0</span></p></li>
</ul>
<h2 id="quadratic-optimisation"><span class="header-section-number">1.4</span> Quadratic optimisation</h2>
<h3 id="the-quadratic-optimisation-problem"><span class="header-section-number">1.4.1</span> The quadratic optimisation problem</h3>
<h2 id="constrainted-non-linear-optimisation"><span class="header-section-number">1.5</span> Constrainted non-linear optimisation</h2>
<h3 id="weak-duality-theorem"><span class="header-section-number">1.5.1</span> Weak duality theorem</h3>
<p>The duality gap (<span class="math inline"><em>p</em><sup>*</sup> − <em>d</em><sup>*</sup></span> is non-negative.</p>
<h3 id="lagrange-multipliers"><span class="header-section-number">1.5.2</span> Lagrange multipliers</h3>
<h3 id="the-dual-problem-for-non-linear-optimisation"><span class="header-section-number">1.5.3</span> The dual problem for non-linear optimisation</h3>
<h3 id="the-weak-duality-theorem"><span class="header-section-number">1.5.4</span> The weak duality theorem</h3>
<h2 id="sort"><span class="header-section-number">1.6</span> Sort</h2>
<h2 id="constrained-convex-optimisation"><span class="header-section-number">1.7</span> Constrained convex optimisation</h2>
<h3 id="slaters-condition"><span class="header-section-number">1.7.1</span> Slater’s condition</h3>
<h4 id="strong-duality"><span class="header-section-number">1.7.1.1</span> Strong duality</h4>
<p>Strong duality is where the duality gap is <span class="math inline">0</span>.</p>
<h4 id="slaters-condition-1"><span class="header-section-number">1.7.1.2</span> Slater’s condition</h4>
<p>Slater’s condition says that strong duality holds if there is an input where the inequality constraints are satisified strictly.</p>
<p>That is they are <span class="math inline"><em>g</em>(<em>x</em>)&lt;0</span>, not <span class="math inline"><em>g</em>(<em>x</em>)≤0</span></p>
<p>This means that the conditions are slack.</p>
<p>This only applies if the problem is convex. That is, if Slater’s condition holds, and the problem is convex, then strong duality holds.</p>
<h3 id="the-strong-duality-theorem"><span class="header-section-number">1.7.2</span> The strong duality theorem</h3>
<h3 id="karush-kuhn-tucker-conditions"><span class="header-section-number">1.7.3</span> Karush-Kuhn-Tucker conditions</h3>
<p>If our problem is non-convex, or if Slater’s condition does not hold, how else can be find a solution?</p>
<p>A solution, <span class="math inline"><em>p</em><sup>*</sup></span> can satisify KKT conditions.</p>
<h3 id="unconstrained-envelope-theorem"><span class="header-section-number">1.7.4</span> Unconstrained envelope theorem</h3>
<p>Consider a function which takes two parameters:</p>
<p><span class="math inline"><em>f</em>(<em>x</em>, <em>α</em></span></p>
<p>We want to choose <span class="math inline"><em>x</em></span> to maximise <span class="math inline"><em>f</em></span>, given <span class="math inline"><em>α</em></span>.</p>
<p><span class="math inline"><em>V</em>(<em>α</em>)=sup<sub><em>x</em> ∈ <em>X</em></sub><em>f</em>(<em>x</em>, <em>α</em>)</span></p>
<p>There is a subset of <span class="math inline"><em>X</em></span> where <span class="math inline"><em>f</em>(<em>x</em>, <em>α</em>)=<em>V</em>(<em>α</em>)</span>.</p>
<p><span class="math inline"><em>X</em><sup>*</sup>(<em>α</em>)={<em>x</em> ∈ <em>X</em>|<em>f</em>(<em>x</em>, <em>α</em>)=<em>V</em>(<em>α</em>)}</span></p>
<p>This means that <span class="math inline"><em>V</em>(<em>α</em>)=<em>f</em>(<em>x</em><sup>*</sup>, <em>α</em>)</span> for <span class="math inline"><em>x</em><sup>*</sup> ∈ <em>X</em><sup>*</sup></span>.</p>
<p>Let’s assume that there is only one <span class="math inline"><em>x</em><sup>*</sup></span>.</p>
<p><span class="math inline"><em>V</em>(<em>α</em>)=<em>f</em>(<em>x</em><sup>*</sup>, <em>α</em>)</span></p>
<p>What happens to the value function as we relax <span class="math inline"><em>α</em></span>?</p>
<p><span class="math inline"><em>V</em><sub><em>α</em><sub><em>i</em></sub></sub>(<em>α</em>)=<em>f</em><sub><em>α</em><sub><em>i</em></sub></sub>(<em>x</em><sup>*</sup>(<em>α</em>),<em>α</em>)</span>.</p>
<p><span class="math inline">$V_{\alpha_i}(\alpha )=f_x\dfrac{\delta x^*}{\delta \alpha }+f_{\alpha_i}$</span>.</p>
<p>We know that <span class="math inline"><em>f</em><sub><em>x</em></sub> = 0</span> from first order conditions. So:</p>
<p><span class="math inline"><em>V</em><sub><em>α</em><sub><em>i</em></sub></sub>(<em>α</em>)=<em>f</em><sub><em>α</em><sub><em>i</em></sub></sub></span>.</p>
<p>That is, at the optimum, as the constant is relaxed, we can treat the <span class="math inline"><em>x</em><sup>*</sup></span> as fixed, as the first-order movement is <span class="math inline">0</span>.</p>
