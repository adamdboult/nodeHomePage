
\subsection{Defining linear models}

\subsubsection{Defining}

One option for \(f(X)\) is a linear model.

\(f(X_i)=\hat{Y_i}= \beta_0+\sum_{j=1}^p\beta_iX_{ij}\)

The values for \(\beta \) are the regression coefficients.

So we have:

\(Y_i=\beta_0+\sum_{j=1}^p\beta_iX_{ij}+e(X_i)+e_i\)

We define the error of the estimate as:

\(\epsilon_i=Y_i-\hat{Y_i}\)

\(\epsilon_i=e(X_i)+e_i \)

So:

\(Y_i=\beta_0+\sum_{j=1}^p\beta_iX_{ij}+\epsilon_i\)

The linear model could be wrong for two reasons. No linear model could be appropriate, or the wrong coefficients could be provided for a linear model.

Linear regression if f is a linear function on w. NB: not linear in x necessarily. could have x^2 etc, but still linear in w

