
\subsection{Perceptron (step function)}

\subsubsection{The function}

If the sum is above \(0\), \(a(z)=1\). Otherwise, \(a(z)=0\).

\subsubsection{The derivative}

This has a differential of \(0\) at all point except \(0\), where it is undefined.

\subsubsection{Notes}

This function is not smooth.

These is the activation function used in the perceptron.

Perceptron data needs to be linearly separable to train.

Even if linearly separable, doesn't necessarily get the best outcome?

