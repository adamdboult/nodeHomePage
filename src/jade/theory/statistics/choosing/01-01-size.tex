
\subsection{Sample sizes}

If you're modelling house prices using just size, getting a large sample size won't help too much

Can improve low bias models*** Sample size

Is data size an issue? can artificially restrict training data size and then evaluate error

Training:
+ zero error for low m
+ increases error as m increases, as degrees of freedom/m falls

cv:
+ error decreases as data set increases, more accurate theta
The two curves converge towards each other for v large m

When are large datasets useful?

When all features available:

Predicting house price using just size, won't benefit from more data...

If choosing correct word in sentence (to, too, two), more helpful

If human expert can do it, then more data probably helpful

Expert realtor probably couldn't do much with just size, but speaker could answer other q

Could expert do it?

Low bias algorithms do well with more data

More data good if large number of parameters, or lot of hidden units.

