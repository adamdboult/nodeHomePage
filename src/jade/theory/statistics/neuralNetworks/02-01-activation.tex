
\subsection{Softmax}

The softmax function is often used in the last layer of a classification network.

It takes a vector of dimension \(k\) and returns another vector of the same size. Only, this time all numbers are between \(0\) and \(1\) and the values sum to \(1\).

The softmax function is based on the sigmoid function.

\(a_j(z)=\dfrac{e^{z_j}}{\sum_{i}e^{z_i}}\)

