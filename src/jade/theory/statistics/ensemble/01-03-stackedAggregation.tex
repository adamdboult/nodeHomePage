
\subsection{Stacking and SuperLearner}

\subsubsection{Introduction}

With stacking we take the predictions from each of our classifiers, and then train a new model using these predictions as inputs.

\subsubsection{Hard and soft inputs}

Hard classification (\(0\) or \(1\)) and soft classification (between \(0\) and \(1\)) can be used as inputs.

\subsubsection{Cross validation}

We can select hyper-parameters using cross validation, however there is an issue of using cross validation twice on the same data. Once for the underyling classifiers, and again for the stacked model.

\subsubsection{SuperLearner}

We have \(m\) models.

Part 1: Train each of them on all data.

Part 2: Split the data into k sets

For each set, associate all other data as training

For each fold:
\begin{itemize}
\item Fit each model on the training data
\item Predict on other
\item Create weighted predictor. choose weightings to minimise error
\end{itemize}

Part 3: Use these weightings on the original (unrestricted data) model

